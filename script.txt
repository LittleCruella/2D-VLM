python src/train/train_vlm.py  --wb_name Med3DVLM-Qwen-2.5-1.5B-pretrain --vision_tower "vit2d" --model_name_or_path Qwen/Qwen2.5-1.5B-Instruct --model_type vlm_qwen --pretrain_vision_model output/CLIP/pretrained_ViT.bin --mm_projector_type "mixer" --vision_select_layer -2 --tune_mm_mlp_adapter True --data_root ./data --bf16 True --output_dir ./output/Med3DVLM-Qwen-2.5-1.5B-pretrain --num_train_epochs 1 --per_device_train_batch_size 1 --per_device_eval_batch_size 1 --gradient_accumulation_steps 1 --eval_strategy "no" --eval_accumulation_steps 1 --eval_steps 0.04 --save_strategy "steps" --save_steps 2000 --save_total_limit 1 --learning_rate 1e-4 --weight_decay 0 --warmup_ratio 0.03 --lr_scheduler_type "cosine" --logging_steps 0.001 --gradient_checkpointing False --dataloader_pin_memory True --dataloader_num_workers 4

python src/train/train_vlm.py --wb_name Med3DVLM-Qwen-2.5-1.5B-finetune --vision_tower "vit2d" --model_name_or_path Qwen/Qwen2.5-1.5B-Instruct --model_type vlm_qwen --mm_projector_type "mlp" --lora_enable True --vision_select_layer 0 --pretrain_vision_model output/CLIP/pretrained_ViT.bin --pretrain_mm_mlp_adapter output/Med2DVLM-1.5B-pretrain/mm_projector.bin --data_root ./data --bf16 True --output_dir ./output/Med3DVLM-Qwen-2.5-1.5B-finetune --num_train_epochs 5 --per_device_train_batch_size 6 --per_device_eval_batch_size 4 --gradient_accumulation_steps 1 --eval_strategy "no" --eval_accumulation_steps 1 --eval_steps 0.04 --save_strategy "steps" --save_steps 5000 --save_total_limit 1 --learning_rate 5e-5 --weight_decay 0. --warmup_ratio 0.03 --lr_scheduler_type "cosine" --logging_steps 0.001 --gradient_checkpointing False --dataloader_pin_memory True --dataloader_num_workers 6

python src/utils/merge_lora_weights_and_save_hf_model.py --model_name_or_path Qwen/Qwen2.5-1.5B-Instruct --model_type vlm_qwen --mm_projector_type "mlp" --pretrain_vision_model output/CLIP/pretrained_ViT.bin --vision_tower "vit2d" --model_with_lora output/Med3DVLM-Qwen-2.5-1.5B-finetune/model_with_lora.bin --output_dir ./models/Med3DVLM-Qwen-2.5-1.5B --cache_dir output/original_model






